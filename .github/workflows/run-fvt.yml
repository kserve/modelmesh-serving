name: FVTs

on:
  pull_request:
    branches: [main]
    paths:
      - '**'
      - '!.github/**'
      - '!.tekton/**'
      - '!docs/**'
      - '!**.md'
      - '.github/workflows/run-fvt.yml'

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - uses: actions/setup-go@v2
        with:
          go-version: '1.17.3'
      - name: Setup Minikube
        run: |
          wget --no-verbose https://github.com/kubernetes/minikube/releases/download/v1.21.0/minikube-linux-amd64
          sudo cp minikube-linux-amd64 /usr/local/bin/minikube
          sudo chmod 755 /usr/local/bin/minikube
          sudo apt-get install -y conntrack socat
          minikube start --driver=none --kubernetes-version v1.20.7
      - name: Check pods
        run: |
          sleep 30
          kubectl get pods -n kube-system
      - name: Set controller image tag
        run: echo "IMAGE_TAG=$(date +'%Y%m%dT%H%M%S%Z')" >> $GITHUB_ENV
      - name: Update configs
        # Update the image tag and reduce some CPU request amounts to allow FVTs to run
        # on reduced resource environments. Also the RollingUpdate strategy for Runtime deployments
        # is adjusted for these environments.
        run: |
          sed -i 's/newTag:.*$/newTag: '"${{ env.IMAGE_TAG }}"'/' config/manager/kustomization.yaml
          sed -i '0,/cpu:.*$/s/cpu:.*$/cpu: 100m/' \
            config/default/config-defaults.yaml \
            config/runtimes/mlserver-0.x.yaml \
            config/runtimes/triton-2.x.yaml
          sed -i 's/maxSurge:.*$/maxSurge: 0/' config/internal/base/deployment.yaml.tmpl
          sed -i 's/maxUnavailable:.*$/maxUnavailable: 100%/' config/internal/base/deployment.yaml.tmpl
      - name: Build Controller image
        run: |
          make build.develop
          ./scripts/build_docker.sh --target runtime --tag ${{ env.IMAGE_TAG }}
      - name: Install ModelMesh Serving
        run: |
          kubectl create ns modelmesh-serving
          kubectl create ns modelmesh-user
          kubectl apply -f https://raw.githubusercontent.com/kserve/kserve/master/test/crds/serving.kserve.io_inferenceservices.yaml
          ./scripts/install.sh --namespace modelmesh-serving -u modelmesh-user --fvt --dev-mode-logging
      - name: Pre-pull runtime images
        run: |
          docker pull nvcr.io/nvidia/tritonserver:21.06.1-py3
          docker pull seldonio/mlserver:0.5.2
      - name: Check installation
        run: |
          docker images
          kubectl get pods
          kubectl get servingruntimes
      - name: Run FVTs
        run: |
          export NAMESPACE=modelmesh-serving
          make fvt
          export NAMESPACE=modelmesh-user
          make fvt
